# Analise exploratÃ³ria de dados
plot(as.factor(HouseVotes84[,2]))
library(mlbench)
data("HouseVotes84")
View(HouseVotes84)
# Analise exploratÃ³ria de dados
plot(as.factor(HouseVotes84[,2]))
title(main = "Votes cast for issue", xlab = "vote", ylab = "# reps")
plot(as.factor(HouseVotes84[HouseVotes84$Class == 'republican', 2]))
title(main = "Republican votes cast for issue 1", xlab = "vote", ylab = "# reps")
plot(as.factor(HouseVotes84[HouseVotes84$Class == 'republican', 2]))
title(main = "Republican votes cast for issue 1", xlab = "vote", ylab = "# reps")
plot(as.factor(HouseVotes84[HouseVotes84$Class == 'democrat',2]))
title(main = "Democrat votes cast for issue 1", xlab = "vote", ylab = "# reps")
# FunÃ§Ãµes usadas para imputation
# FunÃ§Ã£o que retorna o numeros de NA's por voto e classe (democrat or republican)
na_by_col_class <- function (col,cls){return(sum(is.na(HouseVotes84[,col]) & HouseVotes84$Class==cls))}
p_y_col_class <- function(col,cls){
sum_y <- sum(HouseVotes84[,col] == 'y' & HouseVotes84$Class == cls, na.rm = TRUE)
sum_n <- sum(HouseVotes84[,col] == 'n' & HouseVotes84$Class == cls, na.rm = TRUE)
return(sum_y/(sum_y+sum_n))}
# Carregando o dataset
?HouseVotes84
# Testando a funÃ§Ã£o
p_y_col_class(2,'democrat')
p_y_col_class(2,'republican')
na_by_col_class(2,'democrat')
na_by_col_class(2,'republican')
# Impute missing values
for (i in 2:ncol(HouseVotes84)) {
if(sum(is.na(HouseVotes84[,i])>0)) {
c1 <- which(is.na(HouseVotes84[,i]) & HouseVotes84$Class == 'democrat',arr.ind = TRUE)
c2 <- which(is.na(HouseVotes84[,i]) & HouseVotes84$Class == 'republican',arr.ind = TRUE)
HouseVotes84[c1,i] <- ifelse(runif(na_by_col_class(i,'democrat'))<p_y_col_class(i,'democrat'),'y','n')
HouseVotes84[c2,i] <- ifelse(runif(na_by_col_class(i,'republican'))<p_y_col_class(i,'republican'),'y','n')}
}
# Gerando dados de treino e dados de teste
HouseVotes84[,"train"] <- ifelse(runif(nrow(HouseVotes84)) < 0.80,1,0)
trainColNum <- grep("train",names(HouseVotes84))
# Gerando os dados de treino e de teste a partir da coluna de treino
trainHouseVotes84 <- HouseVotes84[HouseVotes84$train == 1, -trainColNum]
testHouseVotes84 <- HouseVotes84[HouseVotes84$train == 0, -trainColNum]
View(trainHouseVotes84)
View(trainColNum)
library(e1071)
# Treine o modelo
?naiveBayes
model <- naiveBayes(Class ~., data = trainHouseVotes84)
pred <- predict(model, testHouseVotes84)
table(pred, HouseVotes84$Class)
View(pred)
table(pred, testHouseVotes84$Class)
install.packages('twitter', 'plyr', 'stringr', 'tm')
install.packages('twitter',  'stringr', 'tm')
install.packages(c('twitter',  'stringr', 'tm'))
library(dplyr)
library(twitteR)
library(stringr)
library(tm)
myapp <- setup_twitter_oauth("3uTFq5nQpZ1apbDr9PPqkxgHx",
"iC3gqkypVLimVJHD1ZU7uCnu2YHKm4CZqN9IUty3IlBoN8K5d2",
access_token = "1314164306544676866-ETJWktr74yRVMi07hLZI06qLuB3fBZ",
access_secret = "VrLLAyBK9ZBzXBvaiINx7dRjWCM41TGNoGuHykk3cT0o6"
)
tw = twitteR::searchTwitter('#realDonaldTrump + #HillaryClinton', n = 1e4, since = '2016-11-08', retryOnRateLimit = 1e3)
d = twitteR::twListToDF(tw)
View(d)
library(dplyr)
library(twitteR)
library(stringr)
library(tm)
myapp <- setup_twitter_oauth("3uTFq5nQpZ1apbDr9PPqkxgHx",
"iC3gqkypVLimVJHD1ZU7uCnu2YHKm4CZqN9IUty3IlBoN8K5d2",
access_token = "1314164306544676866-ETJWktr74yRVMi07hLZI06qLuB3fBZ",
access_secret = "VrLLAyBK9ZBzXBvaiINx7dRjWCM41TGNoGuHykk3cT0o6"
)
tw = twitteR::searchTwitter('#realDonaldTrump + #HillaryClinton', n = 1e8, since = '2016-11-08', retryOnRateLimit = 1e3)
d = twitteR::twListToDF(tw)
View(d)
tw = twitteR::searchTwitter("#beer", n=100)
d = twitteR::twListToDF(tw)
View(d)
tw = twitteR::searchTwitter("#bier", n=100)
d = twitteR::twListToDF(tw)
View(d)
tw = twitteR::searchTwitter("#beer", n=100, lang = 'english')
d = twitteR::twListToDF(tw)
View(d)
("#shoes", n=100, lang = 'english')
d = twitteR::twListToDF(tw)
View(d)
tw = twitteR::searchTwitter("#shoes", n=100, lang = 'english')
d = twitteR::twListToDF(tw)
tw = twitteR::searchTwitter("#shoes", n=100, lang = 'English')
tw = twitteR::searchTwitter("#shoes", n=100)
tw = twitteR::searchTwitter("#beer", n=10000)
d = twitteR::twListToDF(tw)
View(d)
data("crude")
tdm <- TermDocumentMatrix(crude,
control = list(removePunctuation = TRUE,
stopwords = TRUE))
dtm <- DocumentTermMatrix(crude,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
inspect(tdm[202:205, 1:5])
inspect(tdm[c("price", "prices", "texas"), c("127", "144", "191", "194")])
inspect(dtm[1:5, 273:276])
s <- SimpleCorpus(VectorSource(unlist(lapply(crude, as.character))))
m <- TermDocumentMatrix(s,
control = list(removeNumbers = TRUE,
stopwords = TRUE,
stemming = TRUE))
inspect(m[c("price", "texa"), c("127", "144", "191", "194")])
library(tm)
data("crude")
tdm <- TermDocumentMatrix(crude,
control = list(removePunctuation = TRUE,
stopwords = TRUE))
dtm <- DocumentTermMatrix(crude,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
inspect(tdm[202:205, 1:5])
inspect(tdm[c("price", "prices", "texas"), c("127", "144", "191", "194")])
inspect(dtm[1:5, 273:276])
s <- SimpleCorpus(VectorSource(unlist(lapply(crude, as.character))))
m <- TermDocumentMatrix(s,
control = list(removeNumbers = TRUE,
stopwords = TRUE,
stemming = TRUE))
inspect(m[c("price", "texa"), c("127", "144", "191", "194")])
crude
# Configurando o diretÃ³rio de trabalho
# Coloque entre aspas o diretÃ³rio de trabalho que vocÃª estÃ¡ usando no seu computador
setwd("C:/Users/jcval/Documents/Projectos DSA/R_Project2")
getwd()
# Carregando o dataset em um dataframe
credit.df <- read.csv("credit_dataset.csv", header = TRUE, sep = ",")
head(credit.df)
## Convertendo as variÃ¡veis para o tipo fator (categÃ³rica)
to.factors <- function(df, variables){
for (variable in variables){
df[[variable]] <- as.factor(df[[variable]])
}
return(df)
}
## NormalizaÃ§Ã£o
scale.features <- function(df, variables){
for (variable in variables){
df[[variable]] <- scale(df[[variable]], center=T, scale=T)
}
return(df)
}
# Normalizando as variÃ¡veis
numeric.vars <- c("credit.duration.months", "age", "credit.amount")
credit.df <- scale.features(credit.df, numeric.vars)
# VariÃ¡veis do tipo fator
categorical.vars <- c('credit.rating', 'account.balance', 'previous.credit.payment.status',
'credit.purpose', 'savings', 'employment.duration', 'installment.rate',
'marital.status', 'guarantor', 'residence.duration', 'current.assets',
'other.credits', 'apartment.type', 'bank.credits', 'occupation',
'dependents', 'telephone', 'foreign.worker')
credit.df <- to.factors(df = credit.df, variables = categorical.vars)
# Dividindo os dados em treino e teste - 60:40 ratio
indexes <- sample(1:nrow(credit.df), size = 0.6 * nrow(credit.df))
train.data <- credit.df[indexes,]
test.data <- credit.df[-indexes,]
# Feature Selection
library(caret)
library(randomForest)
# FunÃ§Ã£o para seleÃ§Ã£o de variÃ¡veis
run.feature.selection <- function(num.iters=20, feature.vars, class.var){
set.seed(10)
variable.sizes <- 1:10
control <- rfeControl(functions = rfFuncs, method = "cv",
verbose = FALSE, returnResamp = "all",
number = num.iters)
results.rfe <- rfe(x = feature.vars, y = class.var,
sizes = variable.sizes,
rfeControl = control)
return(results.rfe)
}
# Executando a funÃ§Ã£o
rfe.results <- run.feature.selection(feature.vars = train.data[,-1],
class.var = train.data[,1])
# Visualizando os resultados
rfe.results
varImp((rfe.results))
# Criando e Avaliando o Modelo
library(caret)
library(ROCR)
# Biblioteca de utilitÃ¡rios para construÃ§Ã£o de grÃ¡ficos
source("plot_utils.R")
## separate feature and class variables
test.feature.vars <- test.data[,-1]
test.class.var <- test.data[,1]
# Construindo um modelo de regressÃ£o logÃ­stica
formula.init <- "credit.rating ~ ."
formula.init <- as.formula(formula.init)
lr.model <- glm(formula = formula.init, data = train.data, family = "binomial")
# Visualizando o modelo
summary(lr.model)
# Testando o modelo nos dados de teste
lr.predictions <- predict(lr.model, test.data, type="response")
lr.predictions <- round(lr.predictions)
# Avaliando o modelo
confusionMatrix(table(data = lr.predictions, reference = test.class.var), positive = '1')
## Feature selection
formula <- "credit.rating ~ ."
formula <- as.formula(formula)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 2)
model <- train(formula, data = train.data, method = "glm", trControl = control)
importance <- varImp(model, scale = FALSE)
plot(importance)
# Construindo o modelo com as variÃ¡veis selecionadas
formula.new <- "credit.rating ~ account.balance + credit.purpose + previous.credit.payment.status + savings + credit.duration.months"
formula.new <- as.formula(formula.new)
lr.model.new <- glm(formula = formula.new, data = train.data, family = "binomial")
# Visualizando o modelo
summary(lr.model.new)
# Testando o modelo nos dados de teste
lr.predictions.new <- predict(lr.model.new, test.data, type = "response")
lr.predictions.new <- round(lr.predictions.new)
# Avaliando o modelo
confusionMatrix(table(data = lr.predictions.new, reference = test.class.var), positive = '1')
# Criando curvas ROC
lr.model.best <- lr.model
lr.prediction.values <- predict(lr.model.best, test.feature.vars, type = "response")
predictions <- prediction(lr.prediction.values, test.class.var)
par(mfrow = c(1,2))
plot.roc.curve(predictions, title.text = "Curva ROC")
plot.pr.curve(predictions, title.text = "Curva Precision/Recall")
